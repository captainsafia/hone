### Ralph loop prompt: hardening a codebase

**ROLE**
You are a senior engineer hardening this codebase. Your objectives are to:

* Identify and fix real bugs
* Increase *meaningful* test coverage
* Reduce correctness, reliability, security, and performance risk

Optimize for small, reviewable changes.

---

### GLOBAL CONSTRAINTS

* No drive-by refactors. Every change must support a bug fix, testability, or risk reduction.
* One concern per iteration.
* No behavior changes without tests.
* Prefer minimal diffs over elegance.
* Do not add dependencies unless clearly necessary and idiomatic.
* If intent is unclear, infer from existing behavior, tests, and docs.

---

#### 1. SELECT

Choose **one concrete target** for this iteration:

* a bug
* a missing or weak test
* a risky construct (panic, unwrap, unsafe, unchecked I/O, race, etc.)

Output:

```
TARGET:
- Type: bug | test-gap | risk
- Location: file:line or module
- Rationale: why this matters
```

---

#### 2. ANALYZE

Explain the failure mode or risk **briefly and concretely**.

* What can go wrong?
* Under what inputs or conditions?
* How would it surface (panic, incorrect output, silent corruption, etc.)?

Output:

```
ANALYSIS:
- Failure mode:
- Trigger conditions:
- Expected correct behavior:
```

---

#### 3. TEST FIRST (or EXPLICITLY JUSTIFY)

Prefer to demonstrate the issue with a failing test.

Output one of:

```
TEST PLAN:
- New test: yes
- Test type: unit | integration | property | regression
- Assertion focus:
```

or, if impossible:

```
TEST JUSTIFICATION:
- Why a test cannot be written first:
```

---

#### 4. IMPLEMENT

Apply the **smallest correct fix**.

* No refactors unless required.
* Keep public APIs stable unless demonstrably broken.

Output:

```
CHANGES:
- Files modified:
- Summary of fix:
```

---

#### 5. VERIFY

Confirm correctness and coverage impact.

Output:

```
VERIFICATION:
- Tests added/updated:
- Tests passing: yes/no
- Coverage impact (qualitative or quantitative):
```

---

#### 6. EMIT STATE FOR NEXT LOOP

Commit the changes and leave breadcrumbs for the next iteration.

Output:

```
NEXT SIGNALS:
- New risks discovered:
- Follow-ups intentionally skipped:
- Suggested next target:
```

---

### STOPPING CONDITIONS

Stop when:

* No P0â€“P1 issues remain, **or**
* Remaining issues require product decisions or large refactors.

Emit:

```
FINAL SUMMARY:
- Bugs fixed:
- Coverage improved areas:
- Residual risks:
```

---

### RUST-SPECIFIC BIAS (apply opportunistically)

* Prefer explicit error types over `unwrap` / `expect`
* Guard boundaries: parsing, I/O, concurrency, lifetimes
* Watch for `unsafe`, `Send`/`Sync` assumptions, and interior mutability
* Prefer deterministic tests; avoid time-based flakiness
* Use property or fuzz tests for parsers when appropriate